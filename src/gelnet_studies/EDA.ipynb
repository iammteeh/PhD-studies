{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3c18053",
   "metadata": {},
   "source": [
    "# Graphical Elastic Net — Python Analysis Notebook\n",
    "This notebook ingests the CSVs from the reproduction kit (`results/scores_model_*.csv`),summarizes the performance of **glasso (α=1)**, **rope (α=0)**, and **gelnet (α=0.5)**,and produces publication-friendly plots (matplotlib only).**Usage**: Place this notebook in the kit root and run after executing `R/reproduce_simulations.R`.Outputs:- Aggregated tables (per-model, per-method, per-target, ±diag-penalization)- Deltas vs. glasso/rope baselines- Composite ranking (z-normalized metrics)- Matplotlib figures under `plots_py/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b57bd22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 CSV files.\n"
     ]
    }
   ],
   "source": [
    "import os, glob, math\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "KIT_ROOT = Path('.')\n",
    "RES_DIR = KIT_ROOT  / 'data' / 'extended_experiments'\n",
    "PLOT_DIR = KIT_ROOT / 'plots_py'\n",
    "PLOT_DIR.mkdir(exist_ok=True)\n",
    "#csv_files = sorted(RES_DIR.glob('scores_model_*.csv'))\n",
    "csv_files = glob.glob(str(RES_DIR / 'processed_results.csv'))\n",
    "if not csv_files:\n",
    "    print('No simulation CSVs found under results/. Run R/reproduce_simulations.R first.')\n",
    "else:\n",
    "    print(f'Found {len(csv_files)} CSV files.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fc8e3aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>rep</th>\n",
       "      <th>method</th>\n",
       "      <th>alpha</th>\n",
       "      <th>penalize_diag</th>\n",
       "      <th>target</th>\n",
       "      <th>lambda</th>\n",
       "      <th>KL</th>\n",
       "      <th>L2</th>\n",
       "      <th>SP</th>\n",
       "      <th>edges</th>\n",
       "      <th>F1</th>\n",
       "      <th>MCC</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>PRAUC</th>\n",
       "      <th>ROCAUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>glasso</td>\n",
       "      <td>0.20</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.125893</td>\n",
       "      <td>290.787953</td>\n",
       "      <td>717.612391</td>\n",
       "      <td>160.301729</td>\n",
       "      <td>470</td>\n",
       "      <td>0.326870</td>\n",
       "      <td>0.294934</td>\n",
       "      <td>118</td>\n",
       "      <td>4346</td>\n",
       "      <td>352</td>\n",
       "      <td>134</td>\n",
       "      <td>0.300003</td>\n",
       "      <td>0.703888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>glasso</td>\n",
       "      <td>0.35</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.118850</td>\n",
       "      <td>290.137293</td>\n",
       "      <td>717.525143</td>\n",
       "      <td>160.281550</td>\n",
       "      <td>550</td>\n",
       "      <td>0.316708</td>\n",
       "      <td>0.289518</td>\n",
       "      <td>127</td>\n",
       "      <td>4275</td>\n",
       "      <td>423</td>\n",
       "      <td>125</td>\n",
       "      <td>0.298559</td>\n",
       "      <td>0.716390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>glasso</td>\n",
       "      <td>0.50</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.125893</td>\n",
       "      <td>290.787953</td>\n",
       "      <td>717.612391</td>\n",
       "      <td>160.301729</td>\n",
       "      <td>470</td>\n",
       "      <td>0.326870</td>\n",
       "      <td>0.294934</td>\n",
       "      <td>118</td>\n",
       "      <td>4346</td>\n",
       "      <td>352</td>\n",
       "      <td>134</td>\n",
       "      <td>0.300003</td>\n",
       "      <td>0.703888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model  rep  method  alpha  penalize_diag target    lambda          KL  \\\n",
       "0      6   24  glasso   0.20           True    NaN  0.125893  290.787953   \n",
       "1      6   24  glasso   0.35           True    NaN  0.118850  290.137293   \n",
       "2      6   24  glasso   0.50           True    NaN  0.125893  290.787953   \n",
       "\n",
       "           L2          SP  edges        F1       MCC   TP    TN   FP   FN  \\\n",
       "0  717.612391  160.301729    470  0.326870  0.294934  118  4346  352  134   \n",
       "1  717.525143  160.281550    550  0.316708  0.289518  127  4275  423  125   \n",
       "2  717.612391  160.301729    470  0.326870  0.294934  118  4346  352  134   \n",
       "\n",
       "      PRAUC    ROCAUC  \n",
       "0  0.300003  0.703888  \n",
       "1  0.298559  0.716390  \n",
       "2  0.300003  0.703888  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_scores(files):\n",
    "    dfs = []    \n",
    "    for fp in files:\n",
    "        try:\n",
    "            df = pd.read_csv(fp)\n",
    "            dfs.append(df)\n",
    "        except Exception as e:\n",
    "            print(f'Failed to read {fp}: {e}')\n",
    "            if not dfs:\n",
    "                return pd.DataFrame()\n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "scores = load_scores(csv_files)\n",
    "scores.head(3) if not scores.empty else scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a04602e",
   "metadata": {},
   "source": [
    "## Clean-up and sanity checks- Ensure factor types; derive convenient labels- Infer effective target label (already baked into the R kit, but we keep it explicit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "90769d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if scores.empty:\n",
    "    print('No data loaded. Skip the rest of the notebook until results exist.')\n",
    "else:\n",
    "    scores['model'] = scores['model'].astype(int)\n",
    "    scores['rep'] = scores['rep'].astype(int)\n",
    "    scores['penalize_diag'] = scores['penalize_diag'].astype(bool)    # Readable labels    scores['pen_label'] = np.where(scores['penalize_diag'], 'diag✔', 'diag✘')    scores['method_target'] = scores['method'] + ' | ' + scores['target'] + ' | ' + scores['pen_label']    # Sanity    print(scores.groupby(['model','method']).size().head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131ae5ed",
   "metadata": {},
   "source": [
    "## Aggregate metricsWe compute mean and std for KL, L2, SP (↓ is better), and F1, MCC (↑ is better)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b0e40a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not scores.empty:\n",
    "    agg = (scores\n",
    "           .groupby(['model','method','target','penalize_diag'], as_index=False)\n",
    "           .agg({                'KL':['mean','std'],                'L2':['mean','std'],\n",
    "                 'SP':['mean','std'],\n",
    "                 'F1':['mean','std'],\n",
    "                 'MCC':['mean','std']\n",
    "                }))    # flatten columns    agg.columns = ['_'.join([c for c in map(str, col) if c and c!='None']) for col in agg.columns.values]    agg.head()else:    agg = pd.DataFrame()    agg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39908db0",
   "metadata": {},
   "source": [
    "## Baseline deltasFor each model, compute deltas vs **glasso (α=1, target=None, diag✔)** and **rope (α=0, target=None, diag✔)**.Negative delta is better for KL/L2/SP; positive delta is better for F1/MCC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6ed35d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(model, )</th>\n",
       "      <th>(method, )</th>\n",
       "      <th>(target, )</th>\n",
       "      <th>(penalize_diag, )</th>\n",
       "      <th>(KL, mean)</th>\n",
       "      <th>(KL, std)</th>\n",
       "      <th>(L2, mean)</th>\n",
       "      <th>(L2, std)</th>\n",
       "      <th>(SP, mean)</th>\n",
       "      <th>(SP, std)</th>\n",
       "      <th>...</th>\n",
       "      <th>delta_KL_mean_vs_glasso</th>\n",
       "      <th>delta_KL_mean_vs_rope</th>\n",
       "      <th>delta_L2_mean_vs_glasso</th>\n",
       "      <th>delta_L2_mean_vs_rope</th>\n",
       "      <th>delta_SP_mean_vs_glasso</th>\n",
       "      <th>delta_SP_mean_vs_rope</th>\n",
       "      <th>delta_F1_mean_vs_glasso</th>\n",
       "      <th>delta_F1_mean_vs_rope</th>\n",
       "      <th>delta_MCC_mean_vs_glasso</th>\n",
       "      <th>delta_MCC_mean_vs_rope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>gelnet</td>\n",
       "      <td>Eigenvalue</td>\n",
       "      <td>True</td>\n",
       "      <td>116.540240</td>\n",
       "      <td>26.237285</td>\n",
       "      <td>13.289149</td>\n",
       "      <td>3.305848</td>\n",
       "      <td>2.740033</td>\n",
       "      <td>0.522381</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>gelnet</td>\n",
       "      <td>Identity</td>\n",
       "      <td>True</td>\n",
       "      <td>38.355616</td>\n",
       "      <td>5.770517</td>\n",
       "      <td>6.408969</td>\n",
       "      <td>0.597011</td>\n",
       "      <td>1.359886</td>\n",
       "      <td>0.087564</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>gelnet</td>\n",
       "      <td>MSC</td>\n",
       "      <td>True</td>\n",
       "      <td>39.962132</td>\n",
       "      <td>5.957650</td>\n",
       "      <td>5.955649</td>\n",
       "      <td>0.520634</td>\n",
       "      <td>1.266502</td>\n",
       "      <td>0.074755</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>gelnet</td>\n",
       "      <td>Regression</td>\n",
       "      <td>True</td>\n",
       "      <td>55.748269</td>\n",
       "      <td>18.080053</td>\n",
       "      <td>5.554235</td>\n",
       "      <td>0.442481</td>\n",
       "      <td>1.166938</td>\n",
       "      <td>0.088283</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>gelnet</td>\n",
       "      <td>TrueDiag</td>\n",
       "      <td>True</td>\n",
       "      <td>103.850507</td>\n",
       "      <td>16.422496</td>\n",
       "      <td>3.798649</td>\n",
       "      <td>0.978216</td>\n",
       "      <td>0.848410</td>\n",
       "      <td>0.165870</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   (model, ) (method, )  (target, )  (penalize_diag, )  (KL, mean)  (KL, std)  \\\n",
       "0          1     gelnet  Eigenvalue               True  116.540240  26.237285   \n",
       "1          1     gelnet    Identity               True   38.355616   5.770517   \n",
       "2          1     gelnet         MSC               True   39.962132   5.957650   \n",
       "3          1     gelnet  Regression               True   55.748269  18.080053   \n",
       "4          1     gelnet    TrueDiag               True  103.850507  16.422496   \n",
       "\n",
       "   (L2, mean)  (L2, std)  (SP, mean)  (SP, std)  ...  delta_KL_mean_vs_glasso  \\\n",
       "0   13.289149   3.305848    2.740033   0.522381  ...                     None   \n",
       "1    6.408969   0.597011    1.359886   0.087564  ...                     None   \n",
       "2    5.955649   0.520634    1.266502   0.074755  ...                     None   \n",
       "3    5.554235   0.442481    1.166938   0.088283  ...                     None   \n",
       "4    3.798649   0.978216    0.848410   0.165870  ...                     None   \n",
       "\n",
       "   delta_KL_mean_vs_rope  delta_L2_mean_vs_glasso  delta_L2_mean_vs_rope  \\\n",
       "0                   None                     None                   None   \n",
       "1                   None                     None                   None   \n",
       "2                   None                     None                   None   \n",
       "3                   None                     None                   None   \n",
       "4                   None                     None                   None   \n",
       "\n",
       "  delta_SP_mean_vs_glasso delta_SP_mean_vs_rope delta_F1_mean_vs_glasso  \\\n",
       "0                    None                  None                    None   \n",
       "1                    None                  None                    None   \n",
       "2                    None                  None                    None   \n",
       "3                    None                  None                    None   \n",
       "4                    None                  None                    None   \n",
       "\n",
       "  delta_F1_mean_vs_rope delta_MCC_mean_vs_glasso delta_MCC_mean_vs_rope  \n",
       "0                  None                     None                   None  \n",
       "1                  None                     None                   None  \n",
       "2                  None                     None                   None  \n",
       "3                  None                     None                   None  \n",
       "4                  None                     None                   None  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pick_baseline(agg, model, method_name):\n",
    "    rows = agg[(agg['model']==model) & (agg['method']==method_name) &\n",
    "    (agg['target']=='None') & (agg['penalize_diag']==True)]\n",
    "    return rows.iloc[0] if len(rows)>0 else None\n",
    "\n",
    "def D(name, base):\n",
    "    return None if base is None else row[name]- base[name]\n",
    "\n",
    "if not agg.empty:\n",
    "    deltas = []\n",
    "    for m in sorted(agg['model'].unique()):\n",
    "        g_base = pick_baseline(agg, m, 'glasso')\n",
    "        r_base = pick_baseline(agg, m, 'rope')\n",
    "        for _, row in agg[agg['model']==m].iterrows():\n",
    "            d = row.to_dict()                \n",
    "            for metric in ['KL_mean','L2_mean','SP_mean']:\n",
    "                d[f'delta_{metric}_vs_glasso'] = D(metric, g_base)\n",
    "                d[f'delta_{metric}_vs_rope']   = D(metric, r_base)\n",
    "            for metric in ['F1_mean','MCC_mean']:\n",
    "                d[f'delta_{metric}_vs_glasso'] = D(metric, g_base)\n",
    "                d[f'delta_{metric}_vs_rope']   = D(metric, r_base)\n",
    "            deltas.append(d)\n",
    "else:\n",
    "    deltas = pd.DataFrame()\n",
    "    deltas\n",
    "\n",
    "deltas = pd.DataFrame(deltas)\n",
    "deltas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e78d3df",
   "metadata": {},
   "source": [
    "## Composite rankCreate a composite score per (model, method, target, diag) by z-normalizing metrics with the right directionality:- For KL/L2/SP: lower is better (use -z)- For F1/MCC: higher is better (use +z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eb0ffdf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   model  method      target penalize_diag          KL                    L2  \\\n",
      "                                                  mean        std       mean   \n",
      "0      1  gelnet  Eigenvalue          True  116.540240  26.237285  13.289149   \n",
      "1      1  gelnet    Identity          True   38.355616   5.770517   6.408969   \n",
      "2      1  gelnet         MSC          True   39.962132   5.957650   5.955649   \n",
      "3      1  gelnet  Regression          True   55.748269  18.080053   5.554235   \n",
      "4      1  gelnet    TrueDiag          True  103.850507  16.422496   3.798649   \n",
      "5      1  gelnet   vIdentity          True   38.323791   5.776053   6.407294   \n",
      "6      1  glasso  Eigenvalue          True   80.766907  10.652478   8.723980   \n",
      "7      1  glasso    Identity          True   43.028574   6.143519   6.210777   \n",
      "8      1  glasso         MSC          True   43.009449   6.062038   6.206194   \n",
      "9      1  glasso  Regression          True   45.749245   6.518457   6.201954   \n",
      "10     1  glasso    TrueDiag          True   61.250527   9.006237   5.901656   \n",
      "11     1  glasso   vIdentity          True   42.970628   6.057334   6.208363   \n",
      "12     1    rope  Eigenvalue          True  177.588731  20.771658  22.822858   \n",
      "13     1    rope    Identity          True   39.022547   5.693166   8.253426   \n",
      "14     1    rope         MSC          True   31.428198   4.368920   6.151502   \n",
      "15     1    rope  Regression          True   40.068165   7.126849   4.522808   \n",
      "16     1    rope    TrueDiag          True   62.809815  10.459707   2.339285   \n",
      "17     1    rope   vIdentity          True   39.033350   5.718067   8.253157   \n",
      "\n",
      "                    SP                  F1            MCC      \n",
      "         std      mean       std      mean       std mean std  \n",
      "0   3.305848  2.740033  0.522381  0.564594  0.135036  NaN NaN  \n",
      "1   0.597011  1.359886  0.087564  0.552778  0.073266  NaN NaN  \n",
      "2   0.520634  1.266502  0.074755  0.522687  0.047215  NaN NaN  \n",
      "3   0.442481  1.166938  0.088283  0.593422  0.130137  NaN NaN  \n",
      "4   0.978216  0.848410  0.165870  0.672088  0.132714  NaN NaN  \n",
      "5   0.591132  1.359859  0.087677  0.552715  0.073244  NaN NaN  \n",
      "6   1.119967  2.069600  0.292805  0.396446  0.005197  NaN NaN  \n",
      "7   0.334277  1.294367  0.067986  0.455864  0.004860  NaN NaN  \n",
      "8   0.333760  1.294550  0.067122  0.455877  0.004912  NaN NaN  \n",
      "9   0.260021  1.277159  0.055508  0.449425  0.008030  NaN NaN  \n",
      "10  0.135974  1.159540  0.036545  0.427021  0.011658  NaN NaN  \n",
      "11  0.335761  1.294966  0.066786  0.455953  0.004845  NaN NaN  \n",
      "12  2.306413  4.448086  0.463926  0.999974  0.000047  NaN NaN  \n",
      "13  0.404471  1.690952  0.048777  0.999942  0.000077  NaN NaN  \n",
      "14  0.825745  1.133076  0.096036  0.999879  0.000120  NaN NaN  \n",
      "15  0.227402  1.006336  0.041613  0.999887  0.000111  NaN NaN  \n",
      "16  0.139783  0.606825  0.049566  0.999894  0.000108  NaN NaN  \n",
      "17  0.403143  1.690955  0.048787  0.999948  0.000074  NaN NaN  \n",
      "Empty DataFrame\n",
      "Columns: [(model, ), (method, ), (target, ), (penalize_diag, ), (KL, mean), (KL, std), (L2, mean), (L2, std), (SP, mean), (SP, std), (F1, mean), (F1, std), (MCC, mean), (MCC, std), (score, ), (rank, )]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [(model, ), (method, ), (target, ), (penalize_diag, ), (KL, mean), (KL, std), (L2, mean), (L2, std), (SP, mean), (SP, std), (F1, mean), (F1, std), (MCC, mean), (MCC, std), (score, ), (rank, )]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [(model, ), (method, ), (target, ), (penalize_diag, ), (KL, mean), (KL, std), (L2, mean), (L2, std), (SP, mean), (SP, std), (F1, mean), (F1, std), (MCC, mean), (MCC, std), (score, ), (rank, )]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [(model, ), (method, ), (target, ), (penalize_diag, ), (KL, mean), (KL, std), (L2, mean), (L2, std), (SP, mean), (SP, std), (F1, mean), (F1, std), (MCC, mean), (MCC, std), (score, ), (rank, )]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [(model, ), (method, ), (target, ), (penalize_diag, ), (KL, mean), (KL, std), (L2, mean), (L2, std), (SP, mean), (SP, std), (F1, mean), (F1, std), (MCC, mean), (MCC, std), (score, ), (rank, )]\n",
      "Index: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_46453/248136357.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  top = comp.groupby('model', group_keys=False).apply(lambda df: df.nsmallest(10, 'rank'))\n",
      "/tmp/ipykernel_46453/248136357.py:37: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  top = comp.groupby('model', group_keys=False).apply(lambda df: df.nsmallest(10, 'rank'))\n",
      "/tmp/ipykernel_46453/248136357.py:43: RuntimeWarning: Mean of empty slice\n",
      "  return (x - np.nanmean(x)) / (np.nanstd(x) + 1e-12)\n",
      "/home/immanuel/dev/PhD-studies/.venv/lib/python3.12/site-packages/numpy/lib/_nanfunctions_impl.py:2015: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/tmp/ipykernel_46453/248136357.py:43: RuntimeWarning: Mean of empty slice\n",
      "  return (x - np.nanmean(x)) / (np.nanstd(x) + 1e-12)\n",
      "/home/immanuel/dev/PhD-studies/.venv/lib/python3.12/site-packages/numpy/lib/_nanfunctions_impl.py:2015: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
     ]
    }
   ],
   "source": [
    "def zsafe(s: pd.Series) -> pd.Series:\n",
    "    # coerce to numeric, keep index, handle all-NaN or zero-variance cases\n",
    "    s = pd.to_numeric(s, errors='coerce')\n",
    "    mu = np.nanmean(s.values) if s.notna().any() else 0.0\n",
    "    sd = np.nanstd(s.values) if s.notna().any() else 0.0\n",
    "    if not np.isfinite(sd) or sd == 0.0:\n",
    "        # avoid exploding/NaN z-scores; return zeros (neutral contribution)\n",
    "        return pd.Series(np.zeros(len(s)), index=s.index)\n",
    "    return (s - mu) / (sd + 1e-12)\n",
    "\n",
    "if not agg.empty:\n",
    "    rows = []\n",
    "    # group once; don’t mutate `comp` inside the loop\n",
    "    for m, sub in agg.groupby('model', sort=True):\n",
    "        sub = sub.copy()\n",
    "\n",
    "        # Robust MultiIndex selection with tuples:\n",
    "        KLm  = sub[('KL',  'mean')]\n",
    "        L2m  = sub[('L2',  'mean')]\n",
    "        SPm  = sub[('SP',  'mean')]\n",
    "        F1m  = sub[('F1',  'mean')]\n",
    "        MCCm = sub[('MCC', 'mean')]\n",
    "\n",
    "        # Lower-better: KL, L2, SP → negative sign; higher-better: F1, MCC → positive\n",
    "        sub['score'] = (\n",
    "            -zsafe(KLm) + -zsafe(L2m) + -zsafe(SPm) + zsafe(F1m) + zsafe(MCCm)\n",
    "        )\n",
    "\n",
    "        # Higher score ranks better; tie-breaking “min” as you had\n",
    "        sub['rank'] = sub['score'].rank(method='min', ascending=False)\n",
    "\n",
    "        rows.append(sub)\n",
    "\n",
    "    comp = pd.concat(rows, ignore_index=True)\n",
    "    comp = comp.sort_values(['model', 'rank'], kind='mergesort')  # stable sort\n",
    "    # show top-10 per model (optional)\n",
    "    top = comp.groupby('model', group_keys=False).apply(lambda df: df.nsmallest(10, 'rank'))\n",
    "else:\n",
    "    comp = pd.DataFrame()\n",
    "    top = comp\n",
    "\n",
    "def z(x):\n",
    "    return (x - np.nanmean(x)) / (np.nanstd(x) + 1e-12)\n",
    "if not agg.empty:\n",
    "    comp = agg.copy()\n",
    "    rows = []\n",
    "    for m in sorted(comp['model'].unique()):\n",
    "        sub = comp[comp['model']==m].copy()\n",
    "        print(sub)\n",
    "        sub['score'] = (-z(sub[('KL','mean')]) + -z(sub[('L2','mean')]) + -z(sub[('SP','mean')]) + z(sub[('F1','mean')]) + z(sub[('MCC','mean')]))\n",
    "        sub['rank'] = (-sub['score']).rank(method='min')\n",
    "        rows.append(sub)\n",
    "        comp = pd.concat(rows, ignore_index=True)\n",
    "        comp.sort_values(['model','rank']).head(10)\n",
    "else:\n",
    "    comp = pd.DataFrame()\n",
    "    comp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de7c2ab",
   "metadata": {},
   "source": [
    "## PlotsMatplotlib-only, one metric per figure, one figure per model to keep outputs clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "02abec3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved plots_py/model_1_KL_mean.png\n",
      "Saved plots_py/model_2_KL_mean.png\n",
      "Saved plots_py/model_3_KL_mean.png\n",
      "Saved plots_py/model_4_KL_mean.png\n",
      "Saved plots_py/model_5_KL_mean.png\n",
      "Saved plots_py/model_6_KL_mean.png\n",
      "Saved plots_py/model_1_L2_mean.png\n",
      "Saved plots_py/model_2_L2_mean.png\n",
      "Saved plots_py/model_3_L2_mean.png\n",
      "Saved plots_py/model_4_L2_mean.png\n",
      "Saved plots_py/model_5_L2_mean.png\n",
      "Saved plots_py/model_6_L2_mean.png\n",
      "Saved plots_py/model_1_SP_mean.png\n",
      "Saved plots_py/model_2_SP_mean.png\n",
      "Saved plots_py/model_3_SP_mean.png\n",
      "Saved plots_py/model_4_SP_mean.png\n",
      "Saved plots_py/model_5_SP_mean.png\n",
      "Saved plots_py/model_6_SP_mean.png\n",
      "Saved plots_py/model_1_F1_mean.png\n",
      "Saved plots_py/model_2_F1_mean.png\n",
      "Saved plots_py/model_3_F1_mean.png\n",
      "Saved plots_py/model_4_F1_mean.png\n",
      "Saved plots_py/model_5_F1_mean.png\n",
      "Saved plots_py/model_6_F1_mean.png\n",
      "Saved plots_py/model_1_MCC_mean.png\n",
      "Saved plots_py/model_2_MCC_mean.png\n",
      "Saved plots_py/model_3_MCC_mean.png\n",
      "Saved plots_py/model_4_MCC_mean.png\n",
      "Saved plots_py/model_5_MCC_mean.png\n",
      "Saved plots_py/model_6_MCC_mean.png\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def _resolve_series(df, key):\n",
    "    \"\"\"Return a Series for either ('KL','mean') or 'KL_mean' style keys.\"\"\"\n",
    "    if isinstance(key, tuple) and key in df.columns:\n",
    "        return df[key]\n",
    "    if isinstance(key, str):\n",
    "        if key in df.columns:\n",
    "            return df[key]\n",
    "        if \"_\" in key:\n",
    "            a, b = key.split(\"_\", 1)\n",
    "            tup = (a, b)\n",
    "            if tup in df.columns:\n",
    "                return df[tup]\n",
    "    raise KeyError(f\"Metric column {key!r} not found.\")\n",
    "\n",
    "def _key_to_fname(key):\n",
    "    return \"_\".join(key) if isinstance(key, tuple) else key\n",
    "\n",
    "def barplot_metric(comp_df, metric_key, ylabel, fname):\n",
    "    # Ensure x labels exist (method • target [+ diag flag])\n",
    "    if 'method_target' not in comp_df.columns:\n",
    "        diag_flag = np.where(comp_df.get('penalize_diag', False), ' (diag✔)', ' (diag✘)')\n",
    "        comp_df = comp_df.assign(\n",
    "            method_target = comp_df['method'].astype(str) + ' • ' + comp_df['target'].astype(str) + diag_flag\n",
    "        )\n",
    "    models = sorted(comp_df['model'].unique())\n",
    "\n",
    "    for m in models:\n",
    "        sub = comp_df.loc[comp_df['model'] == m].copy()\n",
    "        if sub.empty:\n",
    "            continue\n",
    "\n",
    "        # stable order for readability\n",
    "        sub = sub.sort_values(['method','target','penalize_diag'], kind='mergesort')\n",
    "\n",
    "        y = _resolve_series(sub, metric_key).astype(float).fillna(np.nan)\n",
    "        x = np.arange(len(sub))\n",
    "\n",
    "        plt.figure(figsize=(max(6, len(sub)*0.35), 4.5))\n",
    "        plt.bar(x, y.values)\n",
    "        plt.xticks(x, sub['method_target'], rotation=90)\n",
    "        plt.ylabel(ylabel)\n",
    "        plt.title(f'Model {m} — {ylabel}')\n",
    "        plt.tight_layout()\n",
    "\n",
    "        out = PLOT_DIR / f\"model_{m}_{_key_to_fname(fname)}.png\"\n",
    "        plt.savefig(out, dpi=160)\n",
    "        plt.close()\n",
    "        print('Saved', out)\n",
    "\n",
    "# ---- call it ----\n",
    "if not agg.empty:\n",
    "    # choose keys that work for a MultiIndex (('METRIC','mean')) or flat ('METRIC_mean')\n",
    "    metric_specs = [\n",
    "        (('KL','mean'),  'KL',       'KL_mean'),\n",
    "        (('L2','mean'),  'L2',       'L2_mean'),\n",
    "        (('SP','mean'),  'Spectral', 'SP_mean'),\n",
    "        (('F1','mean'),  'F1',       'F1_mean'),\n",
    "        (('MCC','mean'), 'MCC',      'MCC_mean'),\n",
    "    ]\n",
    "    for key, lab, fname in metric_specs:\n",
    "        barplot_metric(agg, key, lab, fname)\n",
    "\n",
    "\n",
    "#f barplot_metric(comp_df, metric, ylabel, fname):\n",
    "#    models = sorted(comp_df['model'].unique())\n",
    "#    for m in models:\n",
    "#        sub = comp_df[comp_df['model']==m].copy()\n",
    "#        if sub.empty:\n",
    "#            continue\n",
    "#        x = np.arange(len(sub))\n",
    "#        plt.figure()\n",
    "#        plt.bar(x, sub[metric].values)\n",
    "#        plt.xticks(x, sub['method_target'], rotation=90)\n",
    "#        plt.ylabel(ylabel)\n",
    "#        plt.title(f'Model {m} — {ylabel}')\n",
    "#        plt.tight_layout()\n",
    "#        out = PLOT_DIR / f'model_{m}_{fname}.png'\n",
    "#        plt.savefig(out, dpi=160)\n",
    "#        plt.close()\n",
    "#        print('Saved', out)\n",
    "#if not agg.empty:\n",
    "#    print(agg)\n",
    "#    for metric, lab in [(['KL']['mean'],'KL'), ('L2_mean','L2'), ('SP_mean','Spectral'), ('F1_mean','F1'), ('MCC_mean','MCC')]:\n",
    "#            barplot_metric(agg, metric, lab, f'{metric}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d83957d",
   "metadata": {},
   "source": [
    "## Save key tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7605d6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved aggregate tables to plots_py/.\n"
     ]
    }
   ],
   "source": [
    "if not agg.empty:\n",
    "    agg.to_csv(PLOT_DIR / 'aggregate_metrics.csv', index=False)\n",
    "    deltas.to_csv(PLOT_DIR / 'deltas_vs_baselines.csv', index=False)\n",
    "    comp.to_csv(PLOT_DIR / 'composite_rank.csv', index=False)\n",
    "    print('Saved aggregate tables to plots_py/.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce53cbd6-fdbf-4831-9ca7-b8f7dd370c41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PhD-studies",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
