{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3c18053",
   "metadata": {},
   "source": [
    "# Graphical Elastic Net — Python Analysis Notebook\n",
    "This notebook ingests the CSVs from the reproduction kit (`results/scores_model_*.csv`),summarizes the performance of **glasso (α=1)**, **rope (α=0)**, and **gelnet (α=0.5)**,and produces publication-friendly plots (matplotlib only).**Usage**: Place this notebook in the kit root and run after executing `R/reproduce_simulations.R`.Outputs:- Aggregated tables (per-model, per-method, per-target, ±diag-penalization)- Deltas vs. glasso/rope baselines- Composite ranking (z-normalized metrics)- Matplotlib figures under `plots_py/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b57bd22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 CSV files.\n"
     ]
    }
   ],
   "source": [
    "import os, glob, math\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "KIT_ROOT = Path('.')\n",
    "RES_DIR = KIT_ROOT  / 'data' / 'ba_conditional_hamiltonian' # 'extended_experiments' or 'paper_experiments' or 'ba_conditional_hamiltonian'\n",
    "PLOT_DIR = KIT_ROOT / 'plots_py' / 'ba_conditional_hamiltonian' # 'extended_experiments' or 'paper_experiments' or 'ba_conditional_hamiltonian'\n",
    "PLOT_DIR.mkdir(exist_ok=True)\n",
    "#csv_files = sorted(RES_DIR.glob('scores_model_*.csv'))\n",
    "csv_files = glob.glob(str(RES_DIR / 'ba_conditional_hamiltonian.csv')) # adjust for paper_experiments.csv or extended_experiments.csv or ba_conditional_hamiltonian.csv\n",
    "if not csv_files:\n",
    "    print('No simulation CSVs found under results/. Run R/reproduce_simulations.R first.')\n",
    "else:\n",
    "    print(f'Found {len(csv_files)} CSV files.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fc8e3aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>rep</th>\n",
       "      <th>method</th>\n",
       "      <th>alpha</th>\n",
       "      <th>penalize_diag</th>\n",
       "      <th>target</th>\n",
       "      <th>lambda</th>\n",
       "      <th>edges</th>\n",
       "      <th>F1</th>\n",
       "      <th>MCC</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>KL</th>\n",
       "      <th>L2</th>\n",
       "      <th>SP</th>\n",
       "      <th>PRAUC</th>\n",
       "      <th>ROCAUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>glasso</td>\n",
       "      <td>0.20</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.446684</td>\n",
       "      <td>197</td>\n",
       "      <td>0.617234</td>\n",
       "      <td>0.61303</td>\n",
       "      <td>154</td>\n",
       "      <td>4605</td>\n",
       "      <td>43</td>\n",
       "      <td>148</td>\n",
       "      <td>99.480249</td>\n",
       "      <td>53.098451</td>\n",
       "      <td>13.858672</td>\n",
       "      <td>0.68408</td>\n",
       "      <td>0.751762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>glasso</td>\n",
       "      <td>0.35</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.446684</td>\n",
       "      <td>197</td>\n",
       "      <td>0.617234</td>\n",
       "      <td>0.61303</td>\n",
       "      <td>154</td>\n",
       "      <td>4605</td>\n",
       "      <td>43</td>\n",
       "      <td>148</td>\n",
       "      <td>99.480249</td>\n",
       "      <td>53.098451</td>\n",
       "      <td>13.858672</td>\n",
       "      <td>0.68408</td>\n",
       "      <td>0.751762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>glasso</td>\n",
       "      <td>0.50</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.446684</td>\n",
       "      <td>197</td>\n",
       "      <td>0.617234</td>\n",
       "      <td>0.61303</td>\n",
       "      <td>154</td>\n",
       "      <td>4605</td>\n",
       "      <td>43</td>\n",
       "      <td>148</td>\n",
       "      <td>99.480249</td>\n",
       "      <td>53.098451</td>\n",
       "      <td>13.858672</td>\n",
       "      <td>0.68408</td>\n",
       "      <td>0.751762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model  rep  method  alpha  penalize_diag target    lambda  edges        F1  \\\n",
       "0      7    1  glasso   0.20           True    NaN  0.446684    197  0.617234   \n",
       "1      7    1  glasso   0.35           True    NaN  0.446684    197  0.617234   \n",
       "2      7    1  glasso   0.50           True    NaN  0.446684    197  0.617234   \n",
       "\n",
       "       MCC   TP    TN  FP   FN         KL         L2         SP    PRAUC  \\\n",
       "0  0.61303  154  4605  43  148  99.480249  53.098451  13.858672  0.68408   \n",
       "1  0.61303  154  4605  43  148  99.480249  53.098451  13.858672  0.68408   \n",
       "2  0.61303  154  4605  43  148  99.480249  53.098451  13.858672  0.68408   \n",
       "\n",
       "     ROCAUC  \n",
       "0  0.751762  \n",
       "1  0.751762  \n",
       "2  0.751762  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_scores(files):\n",
    "    dfs = []    \n",
    "    for fp in files:\n",
    "        try:\n",
    "            df = pd.read_csv(fp)\n",
    "            dfs.append(df)\n",
    "        except Exception as e:\n",
    "            print(f'Failed to read {fp}: {e}')\n",
    "            if not dfs:\n",
    "                return pd.DataFrame()\n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "scores = load_scores(csv_files)\n",
    "scores.head(3) if not scores.empty else scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a04602e",
   "metadata": {},
   "source": [
    "## Clean-up and sanity checks- Ensure factor types; derive convenient labels- Infer effective target label (already baked into the R kit, but we keep it explicit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "90769d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if scores.empty:\n",
    "    print('No data loaded. Skip the rest of the notebook until results exist.')\n",
    "else:\n",
    "    scores['model'] = scores['model'].astype(int)\n",
    "    scores['rep'] = scores['rep'].astype(int)\n",
    "    scores['penalize_diag'] = scores['penalize_diag'].astype(bool)    # Readable labels    scores['pen_label'] = np.where(scores['penalize_diag'], 'diag✔', 'diag✘')    scores['method_target'] = scores['method'] + ' | ' + scores['target'] + ' | ' + scores['pen_label']    # Sanity    print(scores.groupby(['model','method']).size().head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131ae5ed",
   "metadata": {},
   "source": [
    "## Aggregate metricsWe compute mean and std for KL, L2, SP (↓ is better), and F1, MCC (↑ is better)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b0e40a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not scores.empty:\n",
    "    agg = (scores\n",
    "           .groupby(['model','method','target','penalize_diag'], as_index=False)\n",
    "           .agg({                'KL':['mean','std'],                'L2':['mean','std'],\n",
    "                 'SP':['mean','std'],\n",
    "                 'F1':['mean','std'],\n",
    "                 'MCC':['mean','std']\n",
    "                }))    # flatten columns    agg.columns = ['_'.join([c for c in map(str, col) if c and c!='None']) for col in agg.columns.values]    agg.head()else:    agg = pd.DataFrame()    agg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39908db0",
   "metadata": {},
   "source": [
    "## Baseline deltasFor each model, compute deltas vs **glasso (α=1, target=None, diag✔)** and **rope (α=0, target=None, diag✔)**.Negative delta is better for KL/L2/SP; positive delta is better for F1/MCC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6ed35d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(model, )</th>\n",
       "      <th>(method, )</th>\n",
       "      <th>(target, )</th>\n",
       "      <th>(penalize_diag, )</th>\n",
       "      <th>(KL, mean)</th>\n",
       "      <th>(KL, std)</th>\n",
       "      <th>(L2, mean)</th>\n",
       "      <th>(L2, std)</th>\n",
       "      <th>(SP, mean)</th>\n",
       "      <th>(SP, std)</th>\n",
       "      <th>...</th>\n",
       "      <th>delta_KL_mean_vs_glasso</th>\n",
       "      <th>delta_KL_mean_vs_rope</th>\n",
       "      <th>delta_L2_mean_vs_glasso</th>\n",
       "      <th>delta_L2_mean_vs_rope</th>\n",
       "      <th>delta_SP_mean_vs_glasso</th>\n",
       "      <th>delta_SP_mean_vs_rope</th>\n",
       "      <th>delta_F1_mean_vs_glasso</th>\n",
       "      <th>delta_F1_mean_vs_rope</th>\n",
       "      <th>delta_MCC_mean_vs_glasso</th>\n",
       "      <th>delta_MCC_mean_vs_rope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>gelnet</td>\n",
       "      <td>Eigenvalue</td>\n",
       "      <td>True</td>\n",
       "      <td>62.753143</td>\n",
       "      <td>34.148837</td>\n",
       "      <td>32.041908</td>\n",
       "      <td>3.535017</td>\n",
       "      <td>11.963638</td>\n",
       "      <td>1.914182</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>gelnet</td>\n",
       "      <td>Identity</td>\n",
       "      <td>True</td>\n",
       "      <td>63.424412</td>\n",
       "      <td>19.451505</td>\n",
       "      <td>48.295650</td>\n",
       "      <td>4.341282</td>\n",
       "      <td>14.387701</td>\n",
       "      <td>1.980361</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>gelnet</td>\n",
       "      <td>MSC</td>\n",
       "      <td>True</td>\n",
       "      <td>44.177021</td>\n",
       "      <td>13.168982</td>\n",
       "      <td>43.489146</td>\n",
       "      <td>3.808822</td>\n",
       "      <td>13.715959</td>\n",
       "      <td>1.940285</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>gelnet</td>\n",
       "      <td>Regression</td>\n",
       "      <td>True</td>\n",
       "      <td>50.787765</td>\n",
       "      <td>16.589732</td>\n",
       "      <td>24.996364</td>\n",
       "      <td>2.953083</td>\n",
       "      <td>7.164152</td>\n",
       "      <td>1.113308</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>gelnet</td>\n",
       "      <td>TrueDiag</td>\n",
       "      <td>True</td>\n",
       "      <td>66.134762</td>\n",
       "      <td>23.619560</td>\n",
       "      <td>20.924054</td>\n",
       "      <td>2.838125</td>\n",
       "      <td>5.354552</td>\n",
       "      <td>0.906302</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   (model, ) (method, )  (target, )  (penalize_diag, )  (KL, mean)  (KL, std)  \\\n",
       "0          7     gelnet  Eigenvalue               True   62.753143  34.148837   \n",
       "1          7     gelnet    Identity               True   63.424412  19.451505   \n",
       "2          7     gelnet         MSC               True   44.177021  13.168982   \n",
       "3          7     gelnet  Regression               True   50.787765  16.589732   \n",
       "4          7     gelnet    TrueDiag               True   66.134762  23.619560   \n",
       "\n",
       "   (L2, mean)  (L2, std)  (SP, mean)  (SP, std)  ...  delta_KL_mean_vs_glasso  \\\n",
       "0   32.041908   3.535017   11.963638   1.914182  ...                     None   \n",
       "1   48.295650   4.341282   14.387701   1.980361  ...                     None   \n",
       "2   43.489146   3.808822   13.715959   1.940285  ...                     None   \n",
       "3   24.996364   2.953083    7.164152   1.113308  ...                     None   \n",
       "4   20.924054   2.838125    5.354552   0.906302  ...                     None   \n",
       "\n",
       "   delta_KL_mean_vs_rope  delta_L2_mean_vs_glasso  delta_L2_mean_vs_rope  \\\n",
       "0                   None                     None                   None   \n",
       "1                   None                     None                   None   \n",
       "2                   None                     None                   None   \n",
       "3                   None                     None                   None   \n",
       "4                   None                     None                   None   \n",
       "\n",
       "  delta_SP_mean_vs_glasso delta_SP_mean_vs_rope delta_F1_mean_vs_glasso  \\\n",
       "0                    None                  None                    None   \n",
       "1                    None                  None                    None   \n",
       "2                    None                  None                    None   \n",
       "3                    None                  None                    None   \n",
       "4                    None                  None                    None   \n",
       "\n",
       "  delta_F1_mean_vs_rope delta_MCC_mean_vs_glasso delta_MCC_mean_vs_rope  \n",
       "0                  None                     None                   None  \n",
       "1                  None                     None                   None  \n",
       "2                  None                     None                   None  \n",
       "3                  None                     None                   None  \n",
       "4                  None                     None                   None  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pick_baseline(agg, model, method_name):\n",
    "    rows = agg[(agg['model']==model) & (agg['method']==method_name) &\n",
    "    (agg['target']=='None') & (agg['penalize_diag']==True)]\n",
    "    return rows.iloc[0] if len(rows)>0 else None\n",
    "\n",
    "def D(name, base):\n",
    "    return None if base is None else row[name]- base[name]\n",
    "\n",
    "if not agg.empty:\n",
    "    deltas = []\n",
    "    for m in sorted(agg['model'].unique()):\n",
    "        g_base = pick_baseline(agg, m, 'glasso')\n",
    "        r_base = pick_baseline(agg, m, 'rope')\n",
    "        for _, row in agg[agg['model']==m].iterrows():\n",
    "            d = row.to_dict()                \n",
    "            for metric in ['KL_mean','L2_mean','SP_mean']:\n",
    "                d[f'delta_{metric}_vs_glasso'] = D(metric, g_base)\n",
    "                d[f'delta_{metric}_vs_rope']   = D(metric, r_base)\n",
    "            for metric in ['F1_mean','MCC_mean']:\n",
    "                d[f'delta_{metric}_vs_glasso'] = D(metric, g_base)\n",
    "                d[f'delta_{metric}_vs_rope']   = D(metric, r_base)\n",
    "            deltas.append(d)\n",
    "else:\n",
    "    deltas = pd.DataFrame()\n",
    "    deltas\n",
    "\n",
    "deltas = pd.DataFrame(deltas)\n",
    "deltas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e78d3df",
   "metadata": {},
   "source": [
    "## Composite rankCreate a composite score per (model, method, target, diag) by z-normalizing metrics with the right directionality:- For KL/L2/SP: lower is better (use -z)- For F1/MCC: higher is better (use +z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "eb0ffdf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   model  method      target penalize_diag         KL                    L2  \\\n",
      "                                                 mean        std       mean   \n",
      "0      7  gelnet  Eigenvalue          True  62.753143  34.148837  32.041908   \n",
      "1      7  gelnet    Identity          True  63.424412  19.451505  48.295650   \n",
      "2      7  gelnet         MSC          True  44.177021  13.168982  43.489146   \n",
      "3      7  gelnet  Regression          True  50.787765  16.589732  24.996364   \n",
      "4      7  gelnet    TrueDiag          True  66.134762  23.619560  20.924054   \n",
      "5      7  gelnet   vIdentity          True  63.424412  19.451505  48.295650   \n",
      "6      7  glasso  Eigenvalue          True  43.122291   6.080366  38.445162   \n",
      "7      7  glasso    Identity          True  74.767072   4.827889  48.328329   \n",
      "8      7  glasso         MSC          True  51.682404   3.450883  43.030518   \n",
      "9      7  glasso  Regression          True  42.987815   6.030367  38.447527   \n",
      "10     7  glasso    TrueDiag          True  43.122447   6.081161  38.445129   \n",
      "11     7  glasso   vIdentity          True  74.767072   4.827889  48.328329   \n",
      "12     7    rope  Eigenvalue          True  92.363881   9.910413  30.376583   \n",
      "13     7    rope    Identity          True  22.765765   1.549609  46.283215   \n",
      "14     7    rope         MSC          True  20.959363   0.549253  43.235918   \n",
      "15     7    rope  Regression          True  70.419148   9.576924  22.897070   \n",
      "16     7    rope    TrueDiag          True  86.313038  11.680686  19.047306   \n",
      "17     7    rope   vIdentity          True  22.765765   1.549609  46.283215   \n",
      "\n",
      "                     SP                  F1                 MCC            \n",
      "         std       mean       std      mean       std      mean       std  \n",
      "0   3.535017  11.963638  1.914182  0.511478  0.117224  0.522820  0.101545  \n",
      "1   4.341282  14.387701  1.980361  0.534771  0.092762  0.544386  0.077921  \n",
      "2   3.808822  13.715959  1.940285  0.533098  0.093361  0.542968  0.078696  \n",
      "3   2.953083   7.164152  1.113308  0.508049  0.118297  0.519446  0.102450  \n",
      "4   2.838125   5.354552  0.906302  0.502772  0.125922  0.513838  0.110611  \n",
      "5   4.341282  14.387701  1.980361  0.534771  0.092762  0.544386  0.077921  \n",
      "6   3.316537  12.852280  1.850248  0.602901  0.029349  0.609786  0.027597  \n",
      "7   4.332945  14.383307  1.980602  0.581679  0.032778  0.587142  0.031880  \n",
      "8   3.674266  13.607236  1.933079  0.597535  0.032004  0.603462  0.030120  \n",
      "9   3.316403  12.852324  1.850236  0.602901  0.029349  0.609786  0.027597  \n",
      "10  3.316559  12.852281  1.850248  0.602901  0.029349  0.609786  0.027597  \n",
      "11  4.332945  14.383307  1.980602  0.581679  0.032778  0.587142  0.031880  \n",
      "12  3.327151  11.684164  1.908833  0.118324  0.002243  0.002133  0.002228  \n",
      "13  4.295841  14.102492  1.971178  0.118342  0.002239  0.003911  0.002299  \n",
      "14  3.910204  13.668210  1.935651  0.118334  0.002245  0.003317  0.002186  \n",
      "15  2.218651   6.596444  0.962080  0.118320  0.002240  0.001585  0.002095  \n",
      "16  2.218036   4.869944  0.817554  0.118320  0.002242  0.001781  0.002072  \n",
      "17  4.295841  14.102492  1.971178  0.118342  0.002239  0.003911  0.002299  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_46453/248136357.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  top = comp.groupby('model', group_keys=False).apply(lambda df: df.nsmallest(10, 'rank'))\n",
      "/tmp/ipykernel_46453/248136357.py:37: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  top = comp.groupby('model', group_keys=False).apply(lambda df: df.nsmallest(10, 'rank'))\n"
     ]
    }
   ],
   "source": [
    "def zsafe(s: pd.Series) -> pd.Series:\n",
    "    # coerce to numeric, keep index, handle all-NaN or zero-variance cases\n",
    "    s = pd.to_numeric(s, errors='coerce')\n",
    "    mu = np.nanmean(s.values) if s.notna().any() else 0.0\n",
    "    sd = np.nanstd(s.values) if s.notna().any() else 0.0\n",
    "    if not np.isfinite(sd) or sd == 0.0:\n",
    "        # avoid exploding/NaN z-scores; return zeros (neutral contribution)\n",
    "        return pd.Series(np.zeros(len(s)), index=s.index)\n",
    "    return (s - mu) / (sd + 1e-12)\n",
    "\n",
    "if not agg.empty:\n",
    "    rows = []\n",
    "    # group once; don’t mutate `comp` inside the loop\n",
    "    for m, sub in agg.groupby('model', sort=True):\n",
    "        sub = sub.copy()\n",
    "\n",
    "        # Robust MultiIndex selection with tuples:\n",
    "        KLm  = sub[('KL',  'mean')]\n",
    "        L2m  = sub[('L2',  'mean')]\n",
    "        SPm  = sub[('SP',  'mean')]\n",
    "        F1m  = sub[('F1',  'mean')]\n",
    "        MCCm = sub[('MCC', 'mean')]\n",
    "\n",
    "        # Lower-better: KL, L2, SP → negative sign; higher-better: F1, MCC → positive\n",
    "        sub['score'] = (\n",
    "            -zsafe(KLm) + -zsafe(L2m) + -zsafe(SPm) + zsafe(F1m) + zsafe(MCCm)\n",
    "        )\n",
    "\n",
    "        # Higher score ranks better; tie-breaking “min” as you had\n",
    "        sub['rank'] = sub['score'].rank(method='min', ascending=False)\n",
    "\n",
    "        rows.append(sub)\n",
    "\n",
    "    comp = pd.concat(rows, ignore_index=True)\n",
    "    comp = comp.sort_values(['model', 'rank'], kind='mergesort')  # stable sort\n",
    "    # show top-10 per model (optional)\n",
    "    top = comp.groupby('model', group_keys=False).apply(lambda df: df.nsmallest(10, 'rank'))\n",
    "else:\n",
    "    comp = pd.DataFrame()\n",
    "    top = comp\n",
    "\n",
    "def z(x):\n",
    "    return (x - np.nanmean(x)) / (np.nanstd(x) + 1e-12)\n",
    "if not agg.empty:\n",
    "    comp = agg.copy()\n",
    "    rows = []\n",
    "    for m in sorted(comp['model'].unique()):\n",
    "        sub = comp[comp['model']==m].copy()\n",
    "        print(sub)\n",
    "        sub['score'] = (-z(sub[('KL','mean')]) + -z(sub[('L2','mean')]) + -z(sub[('SP','mean')]) + z(sub[('F1','mean')]) + z(sub[('MCC','mean')]))\n",
    "        sub['rank'] = (-sub['score']).rank(method='min')\n",
    "        rows.append(sub)\n",
    "        comp = pd.concat(rows, ignore_index=True)\n",
    "        comp.sort_values(['model','rank']).head(10)\n",
    "else:\n",
    "    comp = pd.DataFrame()\n",
    "    comp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de7c2ab",
   "metadata": {},
   "source": [
    "## PlotsMatplotlib-only, one metric per figure, one figure per model to keep outputs clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "02abec3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved plots_py/ba_conditional_hamiltonian/model_7_KL_mean.png\n",
      "Saved plots_py/ba_conditional_hamiltonian/model_7_L2_mean.png\n",
      "Saved plots_py/ba_conditional_hamiltonian/model_7_SP_mean.png\n",
      "Saved plots_py/ba_conditional_hamiltonian/model_7_F1_mean.png\n",
      "Saved plots_py/ba_conditional_hamiltonian/model_7_MCC_mean.png\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def _resolve_series(df, key):\n",
    "    \"\"\"Return a Series for either ('KL','mean') or 'KL_mean' style keys.\"\"\"\n",
    "    if isinstance(key, tuple) and key in df.columns:\n",
    "        return df[key]\n",
    "    if isinstance(key, str):\n",
    "        if key in df.columns:\n",
    "            return df[key]\n",
    "        if \"_\" in key:\n",
    "            a, b = key.split(\"_\", 1)\n",
    "            tup = (a, b)\n",
    "            if tup in df.columns:\n",
    "                return df[tup]\n",
    "    raise KeyError(f\"Metric column {key!r} not found.\")\n",
    "\n",
    "def _key_to_fname(key):\n",
    "    return \"_\".join(key) if isinstance(key, tuple) else key\n",
    "\n",
    "def barplot_metric(comp_df, metric_key, ylabel, fname):\n",
    "    # Ensure x labels exist (method • target [+ diag flag])\n",
    "    if 'method_target' not in comp_df.columns:\n",
    "        diag_flag = np.where(comp_df.get('penalize_diag', False), ' (diag✔)', ' (diag✘)')\n",
    "        comp_df = comp_df.assign(\n",
    "            method_target = comp_df['method'].astype(str) + ' • ' + comp_df['target'].astype(str) + diag_flag\n",
    "        )\n",
    "    models = sorted(comp_df['model'].unique())\n",
    "\n",
    "    for m in models:\n",
    "        sub = comp_df.loc[comp_df['model'] == m].copy()\n",
    "        if sub.empty:\n",
    "            continue\n",
    "\n",
    "        # stable order for readability\n",
    "        sub = sub.sort_values(['method','target','penalize_diag'], kind='mergesort')\n",
    "\n",
    "        y = _resolve_series(sub, metric_key).astype(float).fillna(np.nan)\n",
    "        x = np.arange(len(sub))\n",
    "\n",
    "        plt.figure(figsize=(max(6, len(sub)*0.35), 4.5))\n",
    "        plt.bar(x, y.values)\n",
    "        plt.xticks(x, sub['method_target'], rotation=90)\n",
    "        plt.ylabel(ylabel)\n",
    "        plt.title(f'Model {m} — {ylabel}')\n",
    "        plt.tight_layout()\n",
    "\n",
    "        out = PLOT_DIR / f\"model_{m}_{_key_to_fname(fname)}.png\"\n",
    "        plt.savefig(out, dpi=160)\n",
    "        plt.close()\n",
    "        print('Saved', out)\n",
    "\n",
    "# ---- call it ----\n",
    "if not agg.empty:\n",
    "    # choose keys that work for a MultiIndex (('METRIC','mean')) or flat ('METRIC_mean')\n",
    "    metric_specs = [\n",
    "        (('KL','mean'),  'KL',       'KL_mean'),\n",
    "        (('L2','mean'),  'L2',       'L2_mean'),\n",
    "        (('SP','mean'),  'Spectral', 'SP_mean'),\n",
    "        (('F1','mean'),  'F1',       'F1_mean'),\n",
    "        (('MCC','mean'), 'MCC',      'MCC_mean'),\n",
    "    ]\n",
    "    for key, lab, fname in metric_specs:\n",
    "        barplot_metric(agg, key, lab, fname)\n",
    "\n",
    "\n",
    "#f barplot_metric(comp_df, metric, ylabel, fname):\n",
    "#    models = sorted(comp_df['model'].unique())\n",
    "#    for m in models:\n",
    "#        sub = comp_df[comp_df['model']==m].copy()\n",
    "#        if sub.empty:\n",
    "#            continue\n",
    "#        x = np.arange(len(sub))\n",
    "#        plt.figure()\n",
    "#        plt.bar(x, sub[metric].values)\n",
    "#        plt.xticks(x, sub['method_target'], rotation=90)\n",
    "#        plt.ylabel(ylabel)\n",
    "#        plt.title(f'Model {m} — {ylabel}')\n",
    "#        plt.tight_layout()\n",
    "#        out = PLOT_DIR / f'model_{m}_{fname}.png'\n",
    "#        plt.savefig(out, dpi=160)\n",
    "#        plt.close()\n",
    "#        print('Saved', out)\n",
    "#if not agg.empty:\n",
    "#    print(agg)\n",
    "#    for metric, lab in [(['KL']['mean'],'KL'), ('L2_mean','L2'), ('SP_mean','Spectral'), ('F1_mean','F1'), ('MCC_mean','MCC')]:\n",
    "#            barplot_metric(agg, metric, lab, f'{metric}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d83957d",
   "metadata": {},
   "source": [
    "## Save key tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7605d6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved aggregate tables to plots_py/.\n"
     ]
    }
   ],
   "source": [
    "if not agg.empty:\n",
    "    agg.to_csv(PLOT_DIR / 'aggregate_metrics.csv', index=False)\n",
    "    deltas.to_csv(PLOT_DIR / 'deltas_vs_baselines.csv', index=False)\n",
    "    comp.to_csv(PLOT_DIR / 'composite_rank.csv', index=False)\n",
    "    print('Saved aggregate tables to plots_py/.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce53cbd6-fdbf-4831-9ca7-b8f7dd370c41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PhD-studies",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
